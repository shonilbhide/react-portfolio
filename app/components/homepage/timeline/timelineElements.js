let timelineElements = [
    {
      id: 1,
      title: "Analyst",
      location: "Deloitte Consulting",
      description: [
        "Developed and implemented scalable data pipelines for automating ETL process using PySpark, Pandas and Jenkins for 17+ Walmart reports, leveraging Google Cloud Services (BigQuery) for data retrieval, increasing overall efficiency by 12%.",
        "Utilized data analysis and visualization techniques to support various consulting projects, including identifying trends and patterns in client data to inform decision-making.",
        "Directed critical AWS Glue jobs for Vanguard's high-stakes DB migration (20M daily trades) and configured key AWS resources like EC2, Aurora, DynamoDB, SNS, and CloudFront, maintaining professional validation and security measures.",
        "Collaborated in cross-functional teams to develop high-impact data solutions using Agile methodologies."
      ],
      date: "September 2021 - July 2023",
      icon: "work",
    },
    {
      id: 2,
      title: "Research AI/ML Intern",
      location: "Centre for Development of Advanced Computing India",
      description: [
        "Engineered an entity matching framework, enhancing pre-trained Deep Learning architecture (DeepMatcher) with hybrid attribute summarization, and word-level embeddings, and created a novel Blocking algorithm, reducing redundant comparisons by 90%.",
        "Built a graph-based entity linking system on Neo4j (using Graph algorithms and Graph queries). This system can be accessed by the user from a website designed in JavaScript that provides options for data filtering and visualizations.",
        "Presented research findings at the 5th World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4 2021) and published in Springer's LNNS journal series."
      ],
      date: "January 2021 - May 2021",
      icon: "work",
    },
    {
      id: 3,
      title: "Software Development Intern",
      location: "Whizible",
      description: [
        "Analyzed customer data and crafted a customizable data visualization dashboard using Flask and Plotly to improve user satisfaction by 7%.",
        "Developed dynamic dashboards to visualize KPI metrics using Python libraries like Pandas and Matplotlib.",
        "Developed an NLP-powered chatbot using spaCy and TensorFlow, addressing user queries and enhancing user experience.",
        "Integrated the tools with existing BI infrastructure using Azure cloud, enhancing overall system functionality and performance."
      ],
      date: "March 2020 - June 2020",
      icon: "work",
    },
    {
      id: 4,
      title: "Data Analytics Intern",
      location: "Pune Municipal Corporation",
      description: [
        "Cleaned and processed 12 noisy public datasets using Pandas and NumPy to be used by various departments of PMC.",
        "Crafted comprehensive visualizations and generated 7 insightful reports from the processed data, leveraging a diverse toolkit including Matplotlib, Tableau and Power BI."
      ],
      date: "June 2019 - July 2019",
      icon: "work",
    },
    {
      id: 5,
      title: "Master of Computer Science",
      location: "North Carolina State University, Raleigh, NC",
      description: [
        "Coursework: Machine Learning on Graphs, Neural Networks and Deep Learning, Software Engineering, Object Oriented Design and Development, Design and Analysis of Algorithms, Human-Computer Interaction."
      ],
      date: "August 2023 - May 2025",
      icon: "school",
    },
    {
      id: 6,
      title: "Bachelor of Technology in Computer Science",
      location: "Maharashtra Institute of Technology, Pune",
      description: [
        "Coursework: Data Structures, Advanced Machine Learning Algorithms, Artificial Intelligence, Big Data Analytics, Data Warehousing and Data Mining, Design and Analysis of Algorithms, Cognitive Computing, and Natural Language Processing."
      ],
      date: "June 2017 - July 2021",
      icon: "school",
    },
  ];
  
  export default timelineElements;
  