export const experiences = [
  {
    id: 1,
    title: 'Analyst',
    company: "Deloitte Consulting",
    duration: "(Sep 2021 - July 2023)",
    description: [
      "Developed scalable data pipelines for automating ETL processes using PySpark, Pandas, and Jenkins for 17+ Walmart reports, increasing efficiency by 12%.",
      "Utilized data analysis and visualization techniques to identify trends and inform decision-making.",
      "Directed AWS Glue jobs for Vanguard's DB migration (20M daily trades) and configured key AWS resources (EC2, Aurora, DynamoDB, SNS, CloudFront).",
      "Collaborated in cross-functional teams to develop high-impact data solutions using Agile methodologies."
    ]
  },
  {
    id: 2,
    title: "Research AI/ML Intern",
    company: "Centre for Development of Advanced Computing, India (C-DAC)",
    duration: "(Jan 2021 - May 2021)",
    description: [
      "Engineered an entity matching framework, enhancing DeepMatcher with hybrid attribute summarization and word-level embeddings, reducing redundant comparisons by 90%.",
      "Built a graph-based entity linking system on Neo4j using graph algorithms and queries, accessible via a JavaScript-based website with data filtering and visualizations.",
      "Presented research findings at WorldS4 2021 and published in Springer's LNNS journal series."
    ]
  },
  {
    id: 3,
    title: "Software Development Intern",
    company: "Whizible",
    duration: "(March 2020 - June 2020)",
    description: [
      "Analyzed customer data and developed a customizable data visualization dashboard using Flask and Plotly, improving user satisfaction by 7%.",
      "Created dynamic dashboards to visualize KPI metrics using Python libraries (Pandas, Matplotlib).",
      "Developed an NLP-powered chatbot using spaCy and TensorFlow, enhancing user experience.",
      "Integrated tools with existing BI infrastructure using Azure cloud, improving system functionality and performance."
    ]
  },
  {
    id: 4,
    title: "Data Analytics Intern",
    company: "Pune Municipal Corporation",
    duration: "(June 2019 - July 2019)",
    description: [
      "Cleaned and processed 12 noisy public datasets using Pandas and NumPy for various PMC departments.",
      "Crafted comprehensive visualizations and generated 7 insightful reports using Matplotlib, Tableau, and Power BI."
    ]
  }
];
